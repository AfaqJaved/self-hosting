version: '3.8'

services:
  ollama:
    image: ollama/ollama
    container_name: ollama
    environment:
      - OLLAMA_NUM_THREADS=12
    volumes:
      - ${OLLAMA_PATH}:/root/.ollama
    #ports:
    #  - "11434:11434"
    restart: unless-stopped
    networks:
      - nginx


  openwebui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: openwebui
    depends_on:
      - ollama
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - WEBUI_PORT=3000
      - WEBUI_BIND_ADDRESS=0.0.0.0
    #ports:
    #  - "3000:8080" using npm
    volumes:
      - ${OPEN_WEB_UI_PATH}:/app/backend/data
    restart: unless-stopped
    networks:
      - nginx


networks:
  nginx:
    external: true